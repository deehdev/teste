
<div align="center">

# ğŸ’¬ **Sistema DistribuÃ­do de Troca de Mensagens**
### **ZeroMQ â€¢ MessagePack â€¢ Lamport Clock â€¢ EleiÃ§Ã£o Bully â€¢ Berkeley Sync â€¢ Docker*


ğŸ“¡ Mensagens privadas â€” ğŸ“¨ Canais pÃºblicos â€” ğŸ¤– Bots automÃ¡ticos â€” ğŸ” ReplicaÃ§Ã£o â€” â± SincronizaÃ§Ã£o  
**Projeto completo para a disciplina CC7261 â€“ Sistemas DistribuÃ­dos**

---

</div>

## ğŸŒ **VisÃ£o Geral**

Este projeto implementa um sistema distribuÃ­do robusto inspirado em IRC/BBS, permitindo:

- ComunicaÃ§Ã£o em tempo real  
- ReplicaÃ§Ã£o ativa entre servidores  
- Balanceamento via broker  
- SincronizaÃ§Ã£o de relÃ³gios  
- PersistÃªncia em disco  
- TolerÃ¢ncia a falhas com eleiÃ§Ã£o automÃ¡tica  

A arquitetura Ã© composta por **9 containers**, todos conectados atravÃ©s do Docker Compose:

- ğŸ–¥ 3 servidores distribuÃ­dos  
- ğŸ“¡ 1 proxy PUB/SUB  
- ğŸ”„ 1 broker REQ/REP  
- ğŸ“ Servidor de referÃªncia  
- ğŸ¤– 2 bots automÃ¡ticos  
- ğŸ‘¤ 1 cliente interativo  

---

## ğŸ§± **Estrutura Completa**
<img width="696" height="487" alt="image" src="https://github.com/user-attachments/assets/daa6aa69-1029-41f3-9500-d714b6a7e3a6" />





---
</div>

## âš™ï¸ **Tecnologias Utilizadas**

| Tecnologia | Uso |
|-----------|-----|
| **Go** | Servidores + REF Server |
| **Node.js** | Cliente interativo |
| **Python** | Bots automÃ¡ticos |
| **ZeroMQ** | REQ/REP e PUB/SUB distribuÃ­do |
| **MessagePack** | SerializaÃ§Ã£o binÃ¡ria compacta |
| **Lamport Clock** | OrdenaÃ§Ã£o causal |
| **Algoritmo Bully** | EleiÃ§Ã£o do coordenador |
| **Berkeley** | SincronizaÃ§Ã£o de relÃ³gio |
| **Docker Compose** | OrquestraÃ§Ã£o dos 9 containers |

---

## ğŸ—„ **PersistÃªncia**

Cada servidor salva seus dados em:

<img width="226" height="225" alt="image" src="https://github.com/user-attachments/assets/b9e066cd-9688-4d51-a1d3-2b6010b350af" />

          

Com:

- Mensagens de canais  
- Mensagens privadas  
- Timestamps  
- Valor do clock lÃ³gico  
- IdentificaÃ§Ã£o do usuÃ¡rio  

---

## ğŸ” MÃ©todo de ReplicaÃ§Ã£o entre Servidores
**MÃ©todo Escolhido: ReplicaÃ§Ã£o via DifusÃ£o (Broadcast) usando PUB/SUB**<br>
Para distribuir as mensagens entre todos os servidores, o sistema utiliza um Proxy PUB/SUB do ZeroMQ (XSUB/XPUB).<br>
A estratÃ©gia adotada Ã© um modelo de replicaÃ§Ã£o ativa, no qual cada servidor recebe e aplica todas as mensagens, mantendo uma cÃ³pia completa do estado.<br>

**Fluxo:**

Um cliente ou bot envia uma mensagem para qualquer servidor usando REQ/REP.<br>
O servidor que recebeu a requisiÃ§Ã£o publica a mensagem no canal correspondente atravÃ©s do socket PUB conectado ao proxy.<br>
O Proxy PUB/SUB distribui essa mensagem para todos os servidores conectados via SUB.<br>
Cada servidor recebe a mesma mensagem, atualiza seu relÃ³gio lÃ³gico e salva localmente em:<br>

- **data/channels.json**<br>
- **data/messages.json**<br>
- **data/users.json**<br>

Mesmo que um servidor caia e volte, ele possui sua cÃ³pia em disco e continuarÃ¡ recebendo as prÃ³ximas mensagens normalmente.<br>

**Garantia de Ordem (RelÃ³gio LÃ³gico de Lamport)**<br>

Como o ZeroMQ nÃ£o garante ordenaÃ§Ã£o, o sistema utiliza um relÃ³gio lÃ³gico para ordenar eventos:<br>
Cada mensagem carrega o campo clock.<br>
Servidores atualizam seu clock com base no clock recebido.<br>
A persistÃªncia utiliza este clock para garantir ordem causal.<br>
Isso evita problemas de reordenamento entre rÃ©plicas.<br>

**ConsistÃªncia Obtida**<br>

O sistema implementa:<br>
âœ” ConsistÃªncia Eventual<br>
  Todos os servidores recebem todas as publicaÃ§Ãµes e convergem para o mesmo estado.<br>
âœ” ReplicaÃ§Ã£o Ativa<br>
  Todos aplicam a mesma operaÃ§Ã£o â€” nÃ£o hÃ¡ servidor â€œprincipalâ€ responsÃ¡vel pelo estado.<br>
âœ” PersistÃªncia Local<br>
  Cada servidor salva suas mensagens em disco, garantindo sobrevivÃªncia a falhas.<br>
  
**Vantagens do MÃ©todo**

- **Alto desempenho:** ZMQ PUB/SUB Ã© extremamente rÃ¡pido e leve.
- **Total descentralizaÃ§Ã£o:** qualquer servidor pode publicar.
- **TolerÃ¢ncia a falhas:** o coordenador pode cair sem perder mensagens.
- **ImplementaÃ§Ã£o simples:** nÃ£o depende de bancos distribuÃ­dos.

**Fluxo resumido:**

1. Cliente â†’ Servidor via REQ/REP  
2. Servidor publica no Proxy (XSUB)  
3. Proxy faz fan-out para todos servidores SUB  
4. Todos atualizam relÃ³gio + persistem localmente  

>**Garantias:**
- ConsistÃªncia eventual  
- Estado idÃªntico entre servidores  
- Total independÃªncia do coordenador

**ConclusÃ£o**
O projeto adota replicaÃ§Ã£o ativa via difusÃ£o usando PUB/SUB do ZeroMQ, esse mÃ©todo mantÃ©m todos os servidores sincronizados.

---

## ğŸ‘‘ EleiÃ§Ã£o (Bully) + SincronizaÃ§Ã£o Berkeley
- O maior rank vence a eleiÃ§Ã£o.  
- Coordenador divulga no tÃ³pico `servers`  
- A cada 10 mensagens â†’ sincronizaÃ§Ã£o de relÃ³gio fÃ­sico  
- `docker stop server_c`  
- Veja outro servidor ser eleito coordenador.
  
<img width="692" height="360" alt="image" src="https://github.com/user-attachments/assets/e33b6228-7dc9-4a2d-95d3-8ebc31e04b13" />

 
<img width="698" height="348" alt="image" src="https://github.com/user-attachments/assets/770a3f40-3597-4895-abbc-b748619fdfd0" />

 
<img width="1231" height="351" alt="image" src="https://github.com/user-attachments/assets/76655699-540e-46ac-ad59-1b0b87914254" />

 
<img width="1324" height="333" alt="image" src="https://github.com/user-attachments/assets/a7a57ac8-bbdd-4aaf-b06f-4190fa888424" />



<img width="1181" height="160" alt="image" src="https://github.com/user-attachments/assets/55238dc1-1ea8-49be-adc9-594b024a5b83" />

## ğŸš€ Como Executar

//Construir o ambiente<br>
docker-compose build

//Subir os contÃªineres<br>
docker-compose up



## ğŸ–¥ Acessar Cliente

docker exec -it client bash ou<br>
docker compose run --rm client<br>
node client.js<br>
---

## ğŸ’» Comandos do Cliente

| Comando                 | FunÃ§Ã£o                                |
|-------------------------|----------------------------------------|
| `login <nome>`          | Faz login                              |
| `users`                 | Lista usuÃ¡rios                         |
| `channels`              | Lista canais                           |
| `channel <nome>`        | Cria um novo canal                     |
| `subscribe <topico>`    | Inscreve no canal                      |
| `publish <canal> <msg>` | Publica uma mensagem em um canal       |
| `message <user> <msg>`  | Envia uma mensagem privada a um usuÃ¡rio |

 **Login**
 
<img width="634" height="173" alt="image" src="https://github.com/user-attachments/assets/0da1b852-455e-465f-b1b4-ac8a4e5ae34c" />

**users**

<img width="578" height="225" alt="image" src="https://github.com/user-attachments/assets/7306d17d-5b97-4040-83af-a4475b8159a9" />

**channel**

<img width="600" height="124" alt="image" src="https://github.com/user-attachments/assets/20750926-6808-4513-9596-9058f11f3c9a" />

**channels**

<img width="592" height="165" alt="image" src="https://github.com/user-attachments/assets/096de960-cb12-4f67-b6c6-c35cc80295a0" />

**message**

<img width="1324" height="333" alt="image" src="https://github.com/user-attachments/assets/4c578419-fdd7-49ce-9d2a-47975b5ce582" />

**subscribe**

<img width="560" height="364" alt="image" src="https://github.com/user-attachments/assets/0194224e-8709-4c93-8b09-e2a7870b02db" />

---

## ğŸ” Ver Logs dos Servidores

```bash
# Construir o ambiente
docker-compose build

# Subir os contÃªineres
docker-compose up

# ğŸ” Ver Logs dos Servidores


// Construir o ambiente
docker-compose build

// Subir os contÃªineres
docker-compose up


## ğŸ¤– Bots AutomÃ¡ticos

**O que fazem os bots:**
- Criam um usuÃ¡rio aleatÃ³rio  
- Escolhem um canal  
- Enviam mensagens aleatÃ³rias  
- Recebem mensagens pÃºblicas e privadas


## ğŸ§© Servidor de ReferÃªncia (Go)

**FunÃ§Ãµes do servidor de referÃªncia:**

- Armazena:
  - nomes dos servidores
  - endereÃ§os
  - ranks
- Entrega rank ao servidor  
- Monitora heartbeat  
- Expira servidores inativos  
- Fornece lista de ranks  
- Elege o coordenador  

  
## â± RelÃ³gio LÃ³gico (Lamport)

"clock": <contador lÃ³gico>

**Regras:**
- Antes de enviar â†’ `clock++`  
- Ao receber â†’ `clock = max(local, recebido) + 1`

**Garantias:**
âœ” OrdenaÃ§Ã£o causal  
âœ” ReplicaÃ§Ãµes consistentes  
âœ” Logs persistidos na mesma ordem em todos os servidores


## ğŸ•’ SincronizaÃ§Ã£o do RelÃ³gio FÃ­sico (Algoritmo de Berkeley)

- O coordenador consulta outros servidores  
- Calcula mÃ©dia dos desvios  
- Envia ajustes  
- Sincroniza a cada 10 mensagens  
- Se coordenador falhar â†’ eleiÃ§Ã£o ocorre.


## ğŸ‘¤ Autor: Deise Adriana Silva AraÃºjo

Projeto desenvolvido para a disciplina  
CC7261 â€” Sistemas DistribuÃ­dos  
Entregue como soluÃ§Ã£o completa das Partes 1 a 5.

---

## ğŸ¤ ContribuiÃ§Ã£o

ContribuiÃ§Ãµes sÃ£o bem-vindas!  









